{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sikoh/DS-Linear-Models/blob/main/Logistic-Regression/DS_LogisticRegression_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IL7kYvSTWqi"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast.\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model.\n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note**\n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfcUhTaWTWqm"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-06T21:02:20.394062Z",
          "start_time": "2023-10-06T21:02:20.118891Z"
        },
        "id": "ey4jgDsGTWqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-06T21:02:20.397217Z",
          "start_time": "2023-10-06T21:02:20.395159Z"
        },
        "id": "dcU7mrBbTWqr"
      },
      "outputs": [],
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "\n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "\n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "\n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "\n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KW6hJFbTWqu"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-06T21:02:26.208748Z",
          "start_time": "2023-10-06T21:02:25.881364Z"
        },
        "id": "HMrFVspbTWqv",
        "outputId": "0c5e2cfe-d1b4-4309-c5bc-14c0bf643e95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "                  Burrito  Yelp  Google Chips  Cost  Hunger  Mass (g)  \\\nDate                                                                    \n2016-01-18    California    3.5     4.2   NaN  6.49     3.0       NaN   \n2016-01-24    California    3.5     3.3   NaN  5.45     3.5       NaN   \n2016-01-24       Carnitas   NaN     NaN   NaN  4.85     1.5       NaN   \n2016-01-24    Carne asada   NaN     NaN   NaN  5.25     2.0       NaN   \n2016-01-27     California   4.0     3.8     x  6.59     4.0       NaN   \n...                   ...   ...     ...   ...   ...     ...       ...   \n2019-08-27      Al Pastor   NaN     NaN   NaN  6.00     1.0       NaN   \n2019-08-27  Chile Relleno   NaN     NaN   NaN  6.00     4.0       NaN   \n2019-08-27     California   NaN     NaN   NaN  7.90     3.0       NaN   \n2019-08-27         Shrimp   NaN     NaN   NaN  7.90     3.0       NaN   \n2019-08-27    Pollo Asado   NaN     NaN   NaN  5.50     3.5       NaN   \n\n            Density (g/mL)  Length  Circum  ...  Lobster  Queso  Egg  \\\nDate                                        ...                        \n2016-01-18             NaN     NaN     NaN  ...      NaN    NaN  NaN   \n2016-01-24             NaN     NaN     NaN  ...      NaN    NaN  NaN   \n2016-01-24             NaN     NaN     NaN  ...      NaN    NaN  NaN   \n2016-01-24             NaN     NaN     NaN  ...      NaN    NaN  NaN   \n2016-01-27             NaN     NaN     NaN  ...      NaN    NaN  NaN   \n...                    ...     ...     ...  ...      ...    ...  ...   \n2019-08-27             NaN    17.0    20.5  ...      NaN    NaN  NaN   \n2019-08-27             NaN    19.0    26.0  ...      NaN    NaN  NaN   \n2019-08-27             NaN    20.0    22.0  ...      NaN    NaN  NaN   \n2019-08-27             NaN    22.5    24.5  ...      NaN    NaN  NaN   \n2019-08-27             NaN    17.0    21.3  ...      NaN    NaN  NaN   \n\n            Mushroom  Bacon  Sushi  Avocado  Corn  Zucchini  Great  \nDate                                                                \n2016-01-18       NaN    NaN    NaN      NaN   NaN       NaN      0  \n2016-01-24       NaN    NaN    NaN      NaN   NaN       NaN      0  \n2016-01-24       NaN    NaN    NaN      NaN   NaN       NaN      0  \n2016-01-24       NaN    NaN    NaN      NaN   NaN       NaN      0  \n2016-01-27       NaN    NaN    NaN      NaN   NaN       NaN      1  \n...              ...    ...    ...      ...   ...       ...    ...  \n2019-08-27       NaN    NaN    NaN      NaN   NaN       NaN      0  \n2019-08-27       NaN    NaN    NaN      NaN   NaN       NaN      1  \n2019-08-27       NaN    NaN    NaN      NaN   NaN       NaN      0  \n2019-08-27       NaN    NaN    NaN      NaN   NaN       NaN      1  \n2019-08-27       NaN    NaN    NaN      NaN   NaN       NaN      1  \n\n[421 rows x 59 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Burrito</th>\n      <th>Yelp</th>\n      <th>Google</th>\n      <th>Chips</th>\n      <th>Cost</th>\n      <th>Hunger</th>\n      <th>Mass (g)</th>\n      <th>Density (g/mL)</th>\n      <th>Length</th>\n      <th>Circum</th>\n      <th>...</th>\n      <th>Lobster</th>\n      <th>Queso</th>\n      <th>Egg</th>\n      <th>Mushroom</th>\n      <th>Bacon</th>\n      <th>Sushi</th>\n      <th>Avocado</th>\n      <th>Corn</th>\n      <th>Zucchini</th>\n      <th>Great</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-01-18</th>\n      <td>California</td>\n      <td>3.5</td>\n      <td>4.2</td>\n      <td>NaN</td>\n      <td>6.49</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2016-01-24</th>\n      <td>California</td>\n      <td>3.5</td>\n      <td>3.3</td>\n      <td>NaN</td>\n      <td>5.45</td>\n      <td>3.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2016-01-24</th>\n      <td>Carnitas</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.85</td>\n      <td>1.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2016-01-24</th>\n      <td>Carne asada</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.25</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2016-01-27</th>\n      <td>California</td>\n      <td>4.0</td>\n      <td>3.8</td>\n      <td>x</td>\n      <td>6.59</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-08-27</th>\n      <td>Al Pastor</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.00</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>20.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-27</th>\n      <td>Chile Relleno</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.00</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2019-08-27</th>\n      <td>California</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.90</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2019-08-27</th>\n      <td>Shrimp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.90</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.5</td>\n      <td>24.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2019-08-27</th>\n      <td>Pollo Asado</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.50</td>\n      <td>3.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>21.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>421 rows Ã— 59 columns</p>\n</div>"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filepath = \"https://raw.githubusercontent.com/bloominstituteoftechnology/DS-Unit-2-Linear-Models/master/data/burritos/burritos.csv\"\n",
        "df = wrangle(filepath)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKpdy7kYTWqz"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcNCfiQvTWq1"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Tt32YNTWq3"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories.\n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SDmpWpxTWq5"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Usa2zzTWq6"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1uJIap3TWq6"
      },
      "outputs": [],
      "source": [
        "X = ...\n",
        "y = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGSYwjLHTWq7"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017.\n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbsiIGfCTWq8"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = ..., ...\n",
        "X_test, y_test = ..., ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2y7auZ4TWq9"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDr4eUxcTWq9"
      },
      "outputs": [],
      "source": [
        "baseline_acc = ...\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X_2BfebTWq-"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features,\n",
        "- a `SimpleImputer` transformer to deal with missing values,\n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and\n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aGvJ2U6TWq_"
      },
      "outputs": [],
      "source": [
        "model_logr = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HeTZed_TWrA"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_logr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B80ZHPuFTWrA"
      },
      "outputs": [],
      "source": [
        "training_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('Training MAE:', training_acc)\n",
        "print('Test MAE:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYBE5hBMTWrB"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYWszXSYTWrC"
      },
      "outputs": [],
      "source": [
        "# Create your horizontal barchart here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhDvycvPTWrC"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soUktNC3TWrE"
      },
      "outputs": [],
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3hK8p58TWrE"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}